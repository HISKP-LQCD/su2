# Developing the sweep-function

One sweep means applying at least one Metropolis-Update to each link in the lattice. This is implemented in the sweep-function.

For each link `U`, a change `U -> R*U`, with `R` a random element drawn from the appropiate gauge group, is considered. the change is accepted with the probability `min(1, exp(-Delta S))`, with `S` the action.
For a simple action `S= beta sum_{r, mu, nu} Re Tr P_{mu nu}(r)`, `Delta S` involves the link whose change was proposed and the staples surrounding that link. The staples do not and must not change during an update.

### Optimizing via `N_hit`

calculating the staples takes time, so it is advantageous to calculate them once, and then propose a change for the same link `N_hit` times.

### Tuning the acceptance rate

The acceptance rate measures what fraction of proposed changes lead to a changed link. To not get stuck in any local extrema of the action, it is desirable to have an acceptance rate between 30-70\%. The random element is drawn from a certain region, determined by a paramter delta. the bigger delta, the bigger the proposed change could be, and bigger changes lead to smaller acceptance rates. 
the acceptance rate is measured once for all links and once only for temporal links, to take anisotropy effects into account. That is why the return value of sweep is a vector. Maybe this could be changed into an array to reduce the overhead?


### Parallelizing

For an update, only the staples, i.e. only links contained in the neighbouring lattice slices are needed. This makes it possible to do odd-even parallelization.

#### Optimizing the random number generators

The time needed for calculating the staples was meitigated by the introduction of `N_hit`. Another bottleneck is the drawing of random numbers, both for the random element as well as the random number needed to implement the probability. A random number generator can only produce one random number at once, and the time to produce this number is not negligible compared to the other operations happening. Thus, a bottleneck would be created if the random numbers to all threads were generated by one single rng. This is solved by using a several engines, one for each thread. They are given to the sweep-function as a vector.

Test were done for `N_hit=10` and `N_hit=1` in 3 dimensions in an isotropic lattice, to check if a vector is really better than one single engine. The code used was that in scaling.cc as of commit 6413be034f0d448e238eb88c7ebfb45f18b9c554.

In both cases, the difference when only one thread was available is negligible. Thus, the performance was measured with the `speedup = time_one_engine / time_vector`.

For each possible number of threads, the time for 500 configurations was measured 5 times, and the mean and standard deviation were calculated. 

For `N_hit=1`, the measurements for one engine and a vector of engines were within each others margin of error, though in most cases, the speedup with one engine was the higher one. The time for the measurements seem to be mostly needeed for getting the staples.

For `N_hit=10`, the measurements with a vector of engines had a higher speedup for each number of threads, the highest speedups differed by about 0.5. 

The test were done at lattice sizes of 8^3 and 16^3, and the behaviour was qualitatively for both sizes. As expected, the number of threads needed to achieve the biggest possible speedup was different, it was 4 for `L=8`and 7 for `L=16`.
